{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5LFLsizZzIaOn2U+ar3cm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BulusuSrikar/DL-Assignment-2/blob/main/Exp_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 1: Install Transformers Library\n",
        "!pip install transformers --quiet\n",
        "\n",
        "# âœ… Step 2: Import Required Libraries\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# âœ… Step 3: Load Pretrained GPT-2 Model and Tokenizer\n",
        "model_name = \"gpt2\"  # You can also use 'gpt2-medium' or 'gpt2-large'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# âœ… Step 4: Define a Prompt to Begin the Lyrics\n",
        "prompt = \"now hush little baby don't you cry everything's gonna be alright\"  # <-- Customize this\n",
        "\n",
        "# âœ… Step 5: Encode and Generate Lyrics\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Faster generation settings (light sampling)\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=80,              # Limit output length\n",
        "    temperature=0.8,            # Creativity level (lower = more conservative)\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "# âœ… Step 6: Decode and Print the Output\n",
        "generated_lyrics = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"\\nðŸŽµ Generated Lyrics:\\n\")\n",
        "print(generated_lyrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E24v756EiQyk",
        "outputId": "f34b8650-8236-4332-fa4d-eb097437f304"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽµ Generated Lyrics:\n",
            "\n",
            "now hush little baby don't you cry everything's gonna be alright with me, and your baby is gonna be happy!\"\n",
            "\n",
            "The moment she stopped crying, the boy's face was filled with tears. It took her a moment to realize what was happening.\n",
            "\n",
            "\"You're not doing anything wrong.\"\n",
            "\n",
            "\"You're my baby!\"\n",
            "\n",
            "\"I promise. I promise.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFW2MBkviRV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}